---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Prof. Yu is currently working at the School of Computer Science, Beijing University of Technology. His research focuses on artificial intelligence and data security. He received his Ph.D. from Beijing University of Technology in 2019, including a joint Ph.D. training period at the University of Melbourne from 2017 to 2018. He earned his Bachelorâ€™s degree in Computer Science and Technology from Beijing University of Technology in 2013. He currently serves as a registered expert in ISO international standard working groups, an executive committee member of the CCF Blockchain Technical Committee, a member of the Big Data Security and Privacy Computing Technical Committee of the Chinese Information Processing Society of China, and a member of the CCF YOCSEF Headquarters Committee. He is also a youth editorial board member of the Journal of Cybersecurity Science and Blockchain: Research and Applications. He serves as a reviewer/PC member for several top-tier international journals and conferences, including IEEE TIFS, IEEE TDSC, IEEE/ACM TON, IEEE TKDE, IEEE TMC, NeurIPS, ICML, and ICLR.


äºæµ·é˜³ï¼Œå‰¯ç ”ç©¶å‘˜ï¼Œç¡•å£«ç”Ÿå¯¼å¸ˆï¼Œä»»èŒäºåŒ—äº¬å·¥ä¸šå¤§å­¦éƒ¨è®¡ç®—æœºå­¦é™¢ï¼Œä¸“æ”»äººå·¥æ™ºèƒ½å’Œæ•°æ®å®‰å…¨ç­‰é¢†åŸŸç ”ç©¶ã€‚2019å¹´æ¯•ä¸šäºåŒ—äº¬å·¥ä¸šå¤§å­¦è·åšå£«å­¦ä½ï¼Œ2017å¹´è‡³2018å¹´åœ¨å¢¨å°”æœ¬å¤§å­¦è¿›è¡Œåšå£«è”åˆåŸ¹å…»ï¼Œ2013å¹´æ¯•ä¸šäºåŒ—äº¬å·¥ä¸šå¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ä¸“ä¸šè·å­¦å£«å­¦ä½ã€‚ç°ä»»ISOå›½é™…æ ‡å‡†å·¥ä½œç»„æ³¨å†Œä¸“å®¶ï¼ŒCCFåŒºå—é“¾ä¸“å§”ä¼šæ‰§è¡Œå§”å‘˜ï¼Œä¸­æ–‡ä¿¡æ¯å­¦ä¼šå¤§æ•°æ®å®‰å…¨ä¸éšç§è®¡ç®—ä¸“å§”å§”å‘˜ï¼ŒCCF YOCSEFæ€»éƒ¨å§”å‘˜ï¼Œç½‘ç»œç©ºé—´å®‰å…¨ç§‘å­¦å­¦æŠ¥å’ŒBlockchain: Research and ApplicationsæœŸåˆŠé’å¹´ç¼–å§”ä¼šå§”å‘˜ã€‚æ‹…ä»»TIFSã€TDSCã€TONã€TKDEã€TMCã€NIPSã€ICMLã€ICLRã€AAAIç­‰å¤šä¸ªå›½é™…é¡¶çº§æœŸåˆŠå’Œä¼šè®®çš„å®¡ç¨¿äººå’Œç¨‹åºå§”å‘˜ä¼šå§”å‘˜ã€‚è¿‘äº”å¹´ï¼Œä»¥ç¬¬ä¸€ä½œè€…/é€šè®¯ä½œè€…ç´¯è®¡å‘è¡¨CCF Aç±»ã€IEEEæ±‡åˆŠåœ¨å†…çš„é«˜æ°´å¹³æœŸåˆŠä¼šè®®è®ºæ–‡30ä½™ç¯‡ï¼ŒåŒ…æ‹¬IEEE TDSCã€IEEE TIFSã€IEEE TCã€IEEE TMCã€IEEE TONã€IEEE TSCã€IWQoSç­‰ã€‚

# ğŸ‰ News
<!-- - *2022.02*: &nbsp;ğŸ‰ğŸ‰ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2022.02*: &nbsp;ğŸ‰ğŸ‰ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. -->

<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>-->

# ğŸ“ Publications

^: Supervised student  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;â€ : Equal contribution &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ğŸ“§: Corresponding author

## Peer-reviewed Articles

<!-- <img src="https://img.shields.io/badge/AAAI-2025-blue?style=flat-square"> Han Zhao, Min Zhang, Wei Zhao, Pengxiang Ding, <u>Siteng Huang</u>, Donglin Wang, &quot;**Cobra: Extending Mamba to Multi-Modal Large Language Model for Efficient Inference**&quot;. In *Proceedings of the 39th AAAI Conference on Artificial Intelligence*. [[arXiv](https://arxiv.org/abs/2403.14520)] [[pdf](https://arxiv.org/pdf/2403.14520.pdf)] [[project page](https://sites.google.com/view/cobravlm)] [[Chinese intro (Zhihu)](https://zhuanlan.zhihu.com/p/688544752)] [[github](https://github.com/h-zhao1997/cobra)] [[demo](https://huggingface.co/spaces/han1997/cobra)] [[video (Youtube)](https://www.youtube.com/watch?v=i0sTdi_yVbc)] [[æœºå™¨ä¹‹å¿ƒ](https://mp.weixin.qq.com/s/KuuNTL_jBRsyhub5_6aXpQ)] [[Twitter@AK](https://twitter.com/_akhaliq/status/1771033002748837953?t=6S4PVZXg6GcXqi_-PFzipw&s=19)] <a class='paper_citations_badges' data='mhpkWSYAAAAJ:Se3iqnhoufwC' href="" target="_blank"></a> <a href="https://github.com/h-zhao1997/cobra" target="_blank"><img src="https://img.shields.io/github/stars/h-zhao1997/cobra?style=social"></a> -->

<!-- <a href="https://dl.acm.org/doi/10.1145/3664647.3680958" target="_blank"><img src="https://img.shields.io/badge/CVPR-2025-red?style=flat-square"></a> Can Cuiâ€ , <u>Siteng Huang</u>â€ , Wenxuan Song, Pengxiang Ding, Zhang Min, Donglin Wang, &quot;**ProFD: Prompt-Guided Feature Disentangling for Occluded Person Re-Identification**&quot;. In *Proceedings of the 32nd ACM International Conference on Multimedia*. [[arXiv](https://arxiv.org/abs/2409.20081)] [[github](https://github.com/Cuixxx/ProFD)] [[OpenReview](https://openreview.net/forum?id=o2axlPlXYY)] -->

<!-- % -----------2026------------- -->
> **2026**

<a href="" target="_blank"><img src="https://img.shields.io/badge/AAAI-2026-red?style=flat-square"></a>	Z. Dong, C. Li, **<u>Yongjian Deng</u>**, H. Chen &quot;**AIR-DR: Adaptive Image Retargeting with Instance Relocation and Dual-guidance Repainting**&quot;. In *The AAAI Conference on Artificial Intelligence (AAAI)*.

<a href="" target="_blank"><img src="https://img.shields.io/badge/IEEE_TMM-2026-blue?style=flat-square"></a>	Q. Zhou, J. Hou, M. Yang, **<u>Yongjian Deng</u>**, Y. Li and J. Xiong, &quot;**Spatially-guided Temporal Aggregation for Robust Event-RGB Optical Flow Estimation**&quot;. In *IEEE Transactions on MultimediaÂ (IEEE TMM)*.

<a href="" target="_blank"><img src="https://img.shields.io/badge/ACM_TOMM-2025-blue?style=flat-square"></a>	Y. Ding^, B. Yao^, Y. Liu^, H. Chen, D. Ding, Z. Yang, Y. Li and **<u>Yongjian DengğŸ“§</u>**, &quot;**EvSAM: Segment Anything Model with Event-based Assistance**&quot;. In *ACM Transactions on Multimedia Computing, Communications, and ApplicationsÂ (ACM TOMM)*.


<!-- % -----------2025------------- -->
> **2025**

<a href="" target="_blank"><img src="https://img.shields.io/badge/NeurIPS-2025-red?style=flat-square"></a>	Yuhan Liu^, LingHui Fu^, Zhen Yang, Hao Chen, Youfu Li, **<u>Yongjian DengğŸ“§</u>**, &quot;**EPA: Boosting Event-based Video Frame Interpolation with Perceptually Aligned Learning**&quot;. In *The Thirty-ninth Annual Conference on Neural Information Processing Systems (NeurIPS)*.


- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**

# ğŸ– Honors and Awards
<!-- - *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. -->
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# ğŸ“– Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# ğŸ’¬ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# ğŸ’» Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.
